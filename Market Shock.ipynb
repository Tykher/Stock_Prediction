{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2528ccf-8769-45f4-b509-1614fdb5fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6373b92f-3278-410f-a8b1-1cf31de17965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Separate scaler for the target variable\n",
    "target_scaler = MinMaxScaler()\n",
    "feature_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea32c28-37fd-46fa-8e8b-ac5acb7a50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca10f01-e2f4-4a07-81c1-ffa09e1e8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e379252a-ef91-46f0-99c6-a2b11711af9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1999-01-22\n",
       "1       1999-01-23\n",
       "2       1999-01-24\n",
       "3       1999-01-25\n",
       "4       1999-01-26\n",
       "           ...    \n",
       "9632    2025-06-06\n",
       "9633    2025-06-07\n",
       "9634    2025-06-08\n",
       "9635    2025-06-09\n",
       "9636    2025-06-10\n",
       "Name: Unnamed: 0, Length: 9637, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b67e0645-c2b9-4add-8b39-8d8b88897fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d4c1d9-7ac0-4694-9e8b-da68df5cc8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged features for Close_diff_NVDA\n",
    "\n",
    "lags_to_add = [1, 2, 3]  # Specify the lags to include\n",
    "\n",
    "for lag in lags_to_add:\n",
    "    df[f'Lag_Close_diff_{lag}'] = df['Close_NVDA'].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d167649-1f4f-4f00-9326-1cfa6414c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddb257a2-a679-4490-899c-6edd984e9d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close_NVDA'] = target_scaler.fit_transform(df[['Close_NVDA']])  # Target variable\n",
    "df[df.columns.difference(['Close_NVDA'])] = feature_scaler.fit_transform(df[df.columns.difference(['Close_NVDA'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1435618-649f-4ee2-a971-544009b7f831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Open_NVDA</th>\n",
       "      <th>Lag_Close_1</th>\n",
       "      <th>MA10_</th>\n",
       "      <th>EMA10_</th>\n",
       "      <th>MA50_</th>\n",
       "      <th>Lag_Close_3</th>\n",
       "      <th>Close_NVDA</th>\n",
       "      <th>Lag_Close_diff_1</th>\n",
       "      <th>Lag_Close_diff_2</th>\n",
       "      <th>Lag_Close_diff_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9632</th>\n",
       "      <td>0.999585</td>\n",
       "      <td>0.931327</td>\n",
       "      <td>0.936900</td>\n",
       "      <td>0.945295</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.845836</td>\n",
       "      <td>0.945133</td>\n",
       "      <td>0.948480</td>\n",
       "      <td>0.936900</td>\n",
       "      <td>0.949819</td>\n",
       "      <td>0.945133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9633</th>\n",
       "      <td>0.999689</td>\n",
       "      <td>0.935772</td>\n",
       "      <td>0.948480</td>\n",
       "      <td>0.953075</td>\n",
       "      <td>0.959206</td>\n",
       "      <td>0.850295</td>\n",
       "      <td>0.949819</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.948480</td>\n",
       "      <td>0.936900</td>\n",
       "      <td>0.949819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9634</th>\n",
       "      <td>0.999792</td>\n",
       "      <td>0.935772</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.953075</td>\n",
       "      <td>0.959206</td>\n",
       "      <td>0.850295</td>\n",
       "      <td>0.936900</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.948480</td>\n",
       "      <td>0.936900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9635</th>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.935772</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.953075</td>\n",
       "      <td>0.959206</td>\n",
       "      <td>0.850295</td>\n",
       "      <td>0.948480</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.948480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9636</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932503</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.958880</td>\n",
       "      <td>0.965555</td>\n",
       "      <td>0.855196</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.963475</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.954572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9637 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Open_NVDA  Lag_Close_1     MA10_    EMA10_     MA50_  \\\n",
       "0       0.000000   0.000053     0.000042  0.000034  0.000034  0.000039   \n",
       "1       0.000104   0.000056     0.000042  0.000034  0.000039  0.000039   \n",
       "2       0.000208   0.000056     0.000069  0.000034  0.000039  0.000039   \n",
       "3       0.000311   0.000056     0.000069  0.000034  0.000039  0.000039   \n",
       "4       0.000415   0.000066     0.000069  0.000034  0.000039  0.000039   \n",
       "...          ...        ...          ...       ...       ...       ...   \n",
       "9632    0.999585   0.931327     0.936900  0.945295  0.953488  0.845836   \n",
       "9633    0.999689   0.935772     0.948480  0.953075  0.959206  0.850295   \n",
       "9634    0.999792   0.935772     0.954572  0.953075  0.959206  0.850295   \n",
       "9635    0.999896   0.935772     0.954572  0.953075  0.959206  0.850295   \n",
       "9636    1.000000   0.932503     0.954572  0.958880  0.965555  0.855196   \n",
       "\n",
       "      Lag_Close_3  Close_NVDA  Lag_Close_diff_1  Lag_Close_diff_2  \\\n",
       "0        0.000042    0.000042          0.000042          0.000042   \n",
       "1        0.000042    0.000069          0.000042          0.000042   \n",
       "2        0.000042    0.000069          0.000069          0.000042   \n",
       "3        0.000042    0.000069          0.000069          0.000069   \n",
       "4        0.000069    0.000047          0.000069          0.000069   \n",
       "...           ...         ...               ...               ...   \n",
       "9632     0.945133    0.948480          0.936900          0.949819   \n",
       "9633     0.949819    0.954572          0.948480          0.936900   \n",
       "9634     0.936900    0.954572          0.954572          0.948480   \n",
       "9635     0.948480    0.954572          0.954572          0.954572   \n",
       "9636     0.954572    0.963475          0.954572          0.954572   \n",
       "\n",
       "      Lag_Close_diff_3  \n",
       "0             0.000042  \n",
       "1             0.000042  \n",
       "2             0.000042  \n",
       "3             0.000042  \n",
       "4             0.000069  \n",
       "...                ...  \n",
       "9632          0.945133  \n",
       "9633          0.949819  \n",
       "9634          0.936900  \n",
       "9635          0.948480  \n",
       "9636          0.954572  \n",
       "\n",
       "[9637 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9a06675-c2fd-479d-87cd-03d2bc5a822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the target column is defined\n",
    "target_column = 'Close_NVDA'\n",
    "sequence_length = 10\n",
    "\n",
    "# Get the index of the target column\n",
    "target_index = df.columns.get_loc(target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df8fc210-73b7-432f-bbe8-a49018db5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sequences\n",
    "X, y = [], []\n",
    "\n",
    "for i in range(len(df) - sequence_length):\n",
    "    X.append(df.iloc[i:i + sequence_length].values)  # Input sequence\n",
    "    y.append(df.iloc[i + sequence_length, target_index])  # Target value\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c47bde37-3024-43ff-8065-914ce21ee0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9627, 10, 11), (9627,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2d88ff6-4518-4a36-8bdc-cb68ce5a8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a NumPy array, excluding the index\n",
    "data_values = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e031b219-e3d0-4c86-807c-1fe6499ebecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize as Python lists\n",
    "X_train, X_val, X_test = [], [], []\n",
    "y_train, y_val, y_test = [], [], []\n",
    "\n",
    "# Split data manually into train, validation, and test sets\n",
    "train_size = int(len(data_values) * 0.7)\n",
    "val_size = int(len(data_values) * 0.85)\n",
    "\n",
    "for i in range(len(data_values) - sequence_length):\n",
    "    if i + sequence_length <= train_size:\n",
    "        # Add to training data\n",
    "        X_train.append(data_values[i:i + sequence_length])  # Input sequence\n",
    "        y_train.append(data_values[i + sequence_length, target_index])  # Target value\n",
    "    elif i + sequence_length <= val_size:\n",
    "        # Add to validation data\n",
    "        X_val.append(data_values[i:i + sequence_length])\n",
    "        y_val.append(data_values[i + sequence_length, target_index])\n",
    "    else:\n",
    "        # Add to test data\n",
    "        X_test.append(data_values[i:i + sequence_length])\n",
    "        y_test.append(data_values[i + sequence_length, target_index])\n",
    "\n",
    "# Convert to NumPy arrays after appending\n",
    "X_train, X_val, X_test = np.array(X_train), np.array(X_val), np.array(X_test)\n",
    "y_train, y_val, y_test = np.array(y_train), np.array(y_val), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4351f860-6930-4005-9f65-26a45a1d5121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    1999-01-22\n",
       " 1    1999-01-23\n",
       " 2    1999-01-24\n",
       " 3    1999-01-25\n",
       " 4    1999-01-26\n",
       " Name: Unnamed: 0, dtype: object,\n",
       " 6745    2017-07-11\n",
       " 6746    2017-07-12\n",
       " 6747    2017-07-13\n",
       " 6748    2017-07-14\n",
       " 6749    2017-07-15\n",
       " Name: Unnamed: 0, dtype: object,\n",
       " 8191    2021-06-26\n",
       " 8192    2021-06-27\n",
       " 8193    2021-06-28\n",
       " 8194    2021-06-29\n",
       " 8195    2021-06-30\n",
       " Name: Unnamed: 0, dtype: object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the indices for splitting\n",
    "train_size = int(len(date) * 0.7)\n",
    "val_size = int(len(date) * 0.85)\n",
    "\n",
    "# Split the date column into training, validation, and test sets\n",
    "date_train = date[:train_size]\n",
    "date_val = date[train_size:val_size]\n",
    "date_test = date[val_size:]\n",
    "\n",
    "# Show the splits for the date column\n",
    "(date_train.head(), date_val.head(), date_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a6d28ee-d494-48df-be38-350e8b7ebff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras import Input\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63df9197-3498-4b1d-88e9-7e2d39c84d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for LSTM\n",
    "sequence_length = 10\n",
    "X, y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7179a561-e37e-4f66-be04-d18a3fe62125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(units_layer1=64, units_layer2=32, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        LSTM(64, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        Dense(1)  # Single output\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "720c8255-2e98-42f4-9af8-2c123385fa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,456</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m19,456\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,521</span> (76.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,521\u001b[0m (76.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,521</span> (76.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,521\u001b[0m (76.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_lstm_model(units_layer1=128, units_layer2=64, dropout_rate=0.2, learning_rate=0.001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b6189ff-cacf-40e6-90ff-a8e218f39037",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2dd2ebb-a32c-43a4-872e-0440499858ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3.1278e-04 - val_loss: 3.3223e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.7496e-07 - val_loss: 1.7162e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9061e-07 - val_loss: 1.2651e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0406e-07 - val_loss: 9.5972e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.2768e-08 - val_loss: 8.1654e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.9059e-08 - val_loss: 7.1520e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.3375e-08 - val_loss: 1.2287e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0561e-07 - val_loss: 7.3940e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.8326e-08 - val_loss: 7.4426e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.0345e-08 - val_loss: 6.9963e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0018e-07 - val_loss: 1.0628e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0520e-07 - val_loss: 8.6140e-06\n",
      "Epoch 13/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4853e-07 - val_loss: 6.4083e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6512e-07 - val_loss: 1.5310e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7416e-07 - val_loss: 8.9456e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0126e-07 - val_loss: 5.5242e-06\n",
      "Epoch 17/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9179e-07 - val_loss: 1.0103e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7184e-07 - val_loss: 1.2216e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.3049e-07 - val_loss: 7.4100e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6775e-07 - val_loss: 1.1743e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.5812e-07 - val_loss: 4.9598e-06\n",
      "Epoch 22/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6693e-07 - val_loss: 4.9292e-06\n",
      "Epoch 23/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9096e-07 - val_loss: 8.6436e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.9231e-07 - val_loss: 9.9863e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.8671e-07 - val_loss: 7.2510e-06\n",
      "Epoch 26/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.3134e-07 - val_loss: 4.6620e-06\n",
      "Epoch 27/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.7332e-07 - val_loss: 5.6544e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.4223e-07 - val_loss: 7.9393e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.5386e-07 - val_loss: 4.1854e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1202e-07 - val_loss: 4.7548e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5142e-07 - val_loss: 5.5087e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4325e-07 - val_loss: 7.3108e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.0603e-07 - val_loss: 3.8350e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0099e-07 - val_loss: 3.8374e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7977e-07 - val_loss: 9.2920e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.2834e-07 - val_loss: 3.7499e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6284e-07 - val_loss: 4.7704e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6785e-07 - val_loss: 1.0893e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.9964e-07 - val_loss: 3.7441e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0832e-07 - val_loss: 3.7808e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6590e-07 - val_loss: 3.6193e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.3343e-07 - val_loss: 6.6009e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7180e-07 - val_loss: 4.2344e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.5340e-07 - val_loss: 3.4098e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.2440e-07 - val_loss: 3.2878e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1901e-07 - val_loss: 3.6557e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.7033e-08 - val_loss: 3.8730e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2159e-07 - val_loss: 3.0678e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.1932e-08 - val_loss: 3.2549e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2826e-07 - val_loss: 3.3057e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x240373a2ed0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2976b380-641e-4fc1-b597-463e6aa74016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Unscaled Test MSE: 66.55397953777101\n",
      "Unscaled Test MAE: 4.923286034079159\n"
     ]
    }
   ],
   "source": [
    "# Unscale y_test and predictions using the target_scaler\n",
    "y_test_unscaled = target_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "predictions_unscaled = target_scaler.inverse_transform(model.predict(X_test).reshape(-1, 1))\n",
    "\n",
    "# Calculate MSE and MAE on unscaled data\n",
    "mse = mean_squared_error(y_test_unscaled, predictions_unscaled)\n",
    "mae = mean_absolute_error(y_test_unscaled, predictions_unscaled)\n",
    "\n",
    "print(f\"Unscaled Test MSE: {mse}\")\n",
    "print(f\"Unscaled Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1054b2-3dbf-4d3c-ae35-7e79b7a75854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
